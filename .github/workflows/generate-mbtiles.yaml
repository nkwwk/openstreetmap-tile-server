name: Generate MBTiles

on:
  workflow_dispatch:
    inputs:
      geofabrik_extract_id:
        description: Geofabrik extract id (e.g. hong-kong)
        required: false
        default: hong-kong
      image_tag:
        description: GHCR image tag to use (e.g. latest, v1.2.3)
        required: false
        default: latest

# cancel outdated jobs for the same reference
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  IMAGE : ghcr.io/${{ github.repository_owner }}/openstreetmap-tile-server
  TAG   : ${{ github.event.inputs.image_tag || 'latest' }}
  GEOFABRIK_EXTRACT_ID: ${{ github.event.inputs.geofabrik_extract_id || 'hong-kong' }}

jobs:
  generate:
    runs-on: ubuntu-latest
    env:
      MOUNT          : /data/database/
      MB_DB_VOLUME   : osm-db-mbtiles
      MB_TILES_VOLUME: osm-tiles-mbtiles
      MB_CONTAINER   : osm-mbtiles
    steps:
    -
      name: Checkout
      uses: actions/checkout@v3
    -
      name: Environment
      run : |
        echo  IMAGE=$(echo ${{ env.IMAGE }} | tr '[:upper:]' '[:lower:]')  >>$GITHUB_ENV
    -
      name: Pull image
      run : |
        docker  pull  ${IMAGE}:${TAG}
    -
      name: Resolve Geofabrik extract
      run : |
        python3 - <<'PY'
        import json
        import os
        import sys
        import urllib.request

        def bbox_from_geometry(geom):
          """Return (min_lon, min_lat, max_lon, max_lat) from GeoJSON geometry."""
          coords = geom.get("coordinates", [])

          def flatten(coords):
            if not coords:
              return []
            if isinstance(coords[0], (int, float)):
              return [coords]
            return [c for part in coords for c in flatten(part)]

          points = flatten(coords)
          if not points:
            return None
          lons = [p[0] for p in points]
          lats = [p[1] for p in points]
          return (min(lons), min(lats), max(lons), max(lats))

        extract_id = os.environ.get("GEOFABRIK_EXTRACT_ID", "hong-kong")
        index_url = "https://download.geofabrik.de/index-v1.json"

        with urllib.request.urlopen(index_url) as response:
          data = json.load(response)

        match = None
        feature = None
        for f in data.get("features", []):
          if f.get("properties", {}).get("id") == extract_id:
            match = f.get("properties", {})
            feature = f
            break

        if not match:
          print(f"::error::Geofabrik extract id '{extract_id}' not found")
          sys.exit(1)

        urls = match.get("urls", {})
        pbf_url = urls.get("pbf")
        poly_url = urls.get("poly")

        if not pbf_url:
          print(f"::error::No PBF URL for extract id '{extract_id}'")
          sys.exit(1)

        with open(os.environ["GITHUB_ENV"], "a") as env:
          env.write(f"GEOFABRIK_PBF_URL={pbf_url}\n")
          if poly_url:
            env.write(f"GEOFABRIK_POLY_URL={poly_url}\n")
          if feature and feature.get("geometry"):
            b = bbox_from_geometry(feature["geometry"])
            if b:
              env.write(f"GEOFABRIK_MINLON={b[0]}\n")
              env.write(f"GEOFABRIK_MINLAT={b[1]}\n")
              env.write(f"GEOFABRIK_MAXLON={b[2]}\n")
              env.write(f"GEOFABRIK_MAXLAT={b[3]}\n")
        PY
    -
      name: Import Geofabrik extract
      run : |
        docker  volume  create  ${MB_DB_VOLUME}
        docker  volume  create  ${MB_TILES_VOLUME}
        docker  run  --rm  --shm-size=128M  -v ${MB_DB_VOLUME}:${MOUNT}  -v ${MB_TILES_VOLUME}:/data/tiles/ \
          -e DOWNLOAD_PBF="${GEOFABRIK_PBF_URL}"  -e DOWNLOAD_POLY="${GEOFABRIK_POLY_URL:-}" \
          ${IMAGE}:${TAG}  import
    -
      name: Start renderd
      run : |
        docker  run  --shm-size=128M  -v ${MB_DB_VOLUME}:${MOUNT}  -v ${MB_TILES_VOLUME}:/data/tiles/ \
          -p 8081:80  -d  --name ${MB_CONTAINER}  ${IMAGE}:${TAG}  run
        sleep 30
        docker  logs  ${MB_CONTAINER}
    -
      name: Pre-render tiles
      run : |
        if [ -n "${GEOFABRIK_MINLON}" ] && [ -n "${GEOFABRIK_MAXLON}" ] && [ -n "${GEOFABRIK_MINLAT}" ] && [ -n "${GEOFABRIK_MAXLAT}" ]; then
          docker  exec  ${MB_CONTAINER}  render_list  -m default  -z 0  -Z 20  -x "${GEOFABRIK_MINLON}"  -X "${GEOFABRIK_MAXLON}"  -y "${GEOFABRIK_MINLAT}"  -Y "${GEOFABRIK_MAXLAT}"
        else
          docker  exec  ${MB_CONTAINER}  render_list  -a  -m default  -z 0  -Z 20
        fi
    -
      name: Smoke test tiles
      run : |
        curl  http://localhost:8081/tile/1/0/0.png  --fail  -o mb-100.png
        curl  http://localhost:8081/tile/1/1/1.png  --fail  -o mb-111.png
        docker  rm  --force  --volumes  ${MB_CONTAINER}
    -
      name: Export MBTiles
      run : |
        mkdir -p mbtiles
        docker  run  --rm  -v ${MB_TILES_VOLUME}:/data/tiles/  -v $PWD/mbtiles:/data/export \
          -e EXPORT_FILE=export/${GEOFABRIK_EXTRACT_ID}.mbtiles  -e EXPORT_MINZOOM=1  -e EXPORT_MAXZOOM=20 \
          ${IMAGE}:${TAG}  export
        ls -lh mbtiles/*.mbtiles
    -
      name: Upload MBTiles
      uses: actions/upload-artifact@v4
      with:
        name: mbtiles-${{ env.GEOFABRIK_EXTRACT_ID }}
        path: mbtiles/*.mbtiles
    -
      name: Cleanup
      if  : ${{ always() }}
      run : |
        docker  rm  --force  --volumes  ${MB_CONTAINER} || true
        docker  volume  rm  --force  ${MB_DB_VOLUME} || true
        docker  volume  rm  --force  ${MB_TILES_VOLUME} || true
        docker  rmi  --force  ${IMAGE}:${TAG} || true
